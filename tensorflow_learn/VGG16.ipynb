{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jpg_path(file_dir='datasets\\\\birds\\\\train\\\\'):\n",
    "    path=[]\n",
    "    clazz=[]\n",
    "    for root, dirs, files in os.walk(file_dir): \n",
    "        if len(dirs)==0:\n",
    "            cls=root[-3:]\n",
    "            cls=[int(cls)]*len(files)\n",
    "            ph=[root+\"\\\\\"+p for p in files]\n",
    "            path.extend(ph)\n",
    "            clazz.extend(cls)\n",
    "    return path,clazz\n",
    "path,clazz=get_jpg_path('datasets\\\\birds\\\\train\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_label(clazz):\n",
    "    index=0\n",
    "    is_insight=set()\n",
    "    hot=[0]*90\n",
    "    onehot=[]\n",
    "    for i in clazz:\n",
    "        if i not in is_insight:\n",
    "            is_insight.add(i)\n",
    "            hot=[0]*90\n",
    "            hot[index]=1\n",
    "            index+=1\n",
    "        onehot.append(hot)\n",
    "    onehot=np.asarray(onehot)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3830, 90)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot=onehot_label(clazz)\n",
    "onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reszie_jpg(path):\n",
    "    imgs=np.zeros(shape=(3830,224,224,3))\n",
    "    index=0\n",
    "    for p in path:\n",
    "        im=Image.open(p)\n",
    "        im=im.resize((224,224))\n",
    "        npim=np.asarray(im)\n",
    "        if npim.shape!=(224,224,3):\n",
    "            print(npim.shape,index)\n",
    "        else:\n",
    "            imgs[index]=npim\n",
    "        index+=1\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224) 84\n",
      "(224, 224) 375\n",
      "(224, 224) 1358\n",
      "(224, 224) 1800\n",
      "(224, 224) 1942\n",
      "(224, 224) 2218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3830, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs=reszie_jpg(path)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From e:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# BLOCK 1\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block1_conv1', input_shape = (224, 224, 3)))   \n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block1_conv2'))\n",
    "model.add(MaxPooling2D(pool_size = (4, 4), strides = (4, 4), name = 'block1_pool'))\n",
    " \n",
    "# BLOCK2\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block2_conv1'))   \n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block2_conv2'))\n",
    "model.add(MaxPooling2D(pool_size = (4, 4), strides = (4, 4), name = 'block2_pool'))\n",
    " \n",
    "# BLOCK3\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block3_conv1'))   \n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block3_conv2'))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block3_conv3'))\n",
    "model.add(MaxPooling2D(pool_size = (4, 4), strides = (4, 4), name = 'block3_pool'))\n",
    " \n",
    "# # BLOCK4\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block4_conv1'))   \n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block4_conv2'))\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block4_conv3'))\n",
    "# model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), name = 'block4_pool'))\n",
    " \n",
    "# # BLOCK5\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block5_conv1'))   \n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block5_conv2'))\n",
    "# model.add(Conv2D(filters = 512, kernel_size = (3, 3), activation = 'relu', padding = 'same', name = 'block5_conv3'))\n",
    "# model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), name = 'block5_pool'))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu', name = 'fc1'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(1024, activation = 'relu', name = 'fc2'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(90, activation = 'softmax', name = 'prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 90)                92250     \n",
      "=================================================================\n",
      "Total params: 5,237,658\n",
      "Trainable params: 5,237,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(0.1),\n",
    "              #loss='mse',\n",
    "              loss='categorical_crossentropy',\n",
    "              #loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtr,xte,ytr,yte=train_test_split(imgs,onehot,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2681/2681 [==============================] - 17s 6ms/sample - loss: 15.9496 - acc: 0.0086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x217037f2ba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtr, ytr, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01072291 0.01073736 0.01125581 0.01095123 0.0113096  0.0107666\n",
      " 0.01106321 0.01082318 0.01129509 0.01089017 0.01120081 0.0111504\n",
      " 0.01118319 0.01125955 0.01096459 0.0114021  0.01105785 0.01115866\n",
      " 0.01116157 0.01091313 0.01103678 0.01116761 0.01089413 0.01094126\n",
      " 0.01089955 0.01081029 0.01145709 0.01129242 0.01128486 0.01131305\n",
      " 0.01096622 0.01094435 0.01094804 0.01117639 0.01106422 0.01119096\n",
      " 0.01124079 0.01117383 0.01109465 0.01147254 0.01104987 0.01121317\n",
      " 0.01110896 0.01131056 0.0114742  0.01111839 0.01111995 0.01107155\n",
      " 0.01121696 0.01123413 0.01079423 0.01094814 0.01092383 0.01124684\n",
      " 0.01107778 0.01112877 0.01088976 0.01136811 0.0112252  0.01028229\n",
      " 0.01106653 0.01084825 0.01123654 0.01096233 0.01123914 0.01120788\n",
      " 0.01081444 0.01118283 0.01129275 0.01107362 0.01164506 0.01120591\n",
      " 0.01084604 0.01109967 0.01090941 0.01093801 0.01128644 0.01105327\n",
      " 0.01169732 0.01086901 0.01095048 0.01121553 0.01123411 0.01128309\n",
      " 0.01134731 0.0112013  0.01100412 0.01116736 0.01137801 0.01130551]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.01072382 0.01073363 0.01125506 0.01094803 0.01130667 0.01076152\n",
      " 0.01106341 0.01082348 0.01129432 0.01089085 0.0111997  0.01115416\n",
      " 0.01118433 0.01125833 0.01096483 0.0114035  0.01105563 0.01115648\n",
      " 0.01116204 0.01091161 0.01103632 0.01116842 0.01089696 0.01094371\n",
      " 0.01090153 0.01081133 0.01145723 0.01129561 0.01128665 0.01131268\n",
      " 0.01096505 0.01094679 0.01094589 0.01117491 0.01106535 0.01118997\n",
      " 0.01124094 0.01117555 0.01109534 0.01147906 0.01104616 0.01121429\n",
      " 0.01110899 0.01131001 0.01147322 0.01112036 0.01111947 0.01107368\n",
      " 0.01121866 0.01123552 0.01079706 0.01094656 0.01092412 0.01124741\n",
      " 0.01107744 0.011129   0.01088904 0.01137179 0.01122499 0.01027186\n",
      " 0.01106951 0.01084742 0.01123262 0.01095538 0.01123508 0.0112076\n",
      " 0.01081617 0.01118494 0.01129327 0.01106907 0.01164584 0.01120774\n",
      " 0.01084568 0.0110937  0.01090883 0.01094105 0.01128496 0.01105028\n",
      " 0.01169572 0.0108711  0.01094893 0.01121826 0.01123313 0.01128541\n",
      " 0.01134971 0.01120456 0.01100653 0.01116921 0.01138006 0.01130794]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.01072962 0.0107086  0.01126128 0.01094068 0.01131789 0.01072507\n",
      " 0.01107643 0.01082239 0.01130378 0.01087134 0.01122147 0.01116111\n",
      " 0.0111768  0.01125622 0.01096951 0.01140757 0.01104783 0.01112693\n",
      " 0.01116725 0.01088859 0.01103754 0.01118944 0.01092041 0.01094768\n",
      " 0.01091021 0.01080364 0.01148272 0.01130983 0.01127773 0.01129355\n",
      " 0.01095597 0.01094662 0.01094944 0.01117294 0.01107316 0.01120727\n",
      " 0.01124563 0.01114982 0.01109307 0.01153023 0.011011   0.01121439\n",
      " 0.01111469 0.01130921 0.0114686  0.01111118 0.01114316 0.01109048\n",
      " 0.0112106  0.01124055 0.01082202 0.01093743 0.01093571 0.01125504\n",
      " 0.01108529 0.01113495 0.01089744 0.01137278 0.01123816 0.01019138\n",
      " 0.01107552 0.01085035 0.01121693 0.01094097 0.01122311 0.01120896\n",
      " 0.01081758 0.01119916 0.01130748 0.01106342 0.01162406 0.01121008\n",
      " 0.01084301 0.01108375 0.01089488 0.01094142 0.01129284 0.01102911\n",
      " 0.01169167 0.01088829 0.01094777 0.01122029 0.01121105 0.01128967\n",
      " 0.01136637 0.01121101 0.01100681 0.01119105 0.01138332 0.0113087 ]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.01071815 0.01072579 0.01125032 0.01094555 0.01130831 0.01074678\n",
      " 0.01106343 0.0108283  0.01129908 0.01087874 0.01120916 0.01115883\n",
      " 0.01118124 0.01126024 0.01096419 0.01140754 0.01104527 0.01114638\n",
      " 0.01116724 0.01089895 0.01103312 0.01117329 0.01090335 0.0109485\n",
      " 0.01090779 0.01080443 0.01145931 0.01129964 0.01127901 0.01131701\n",
      " 0.0109573  0.01094777 0.01094317 0.01117069 0.01106638 0.01120367\n",
      " 0.01124027 0.01116708 0.01109937 0.01150645 0.01103303 0.01120842\n",
      " 0.01110771 0.0113044  0.01147912 0.01111247 0.01112493 0.01108134\n",
      " 0.01122389 0.01123344 0.01080818 0.01094491 0.01093019 0.01125265\n",
      " 0.0110884  0.01113435 0.01089174 0.01137473 0.01123129 0.01023313\n",
      " 0.01107367 0.01084831 0.01122958 0.01093896 0.01122687 0.01120921\n",
      " 0.01081541 0.01119629 0.011301   0.01106424 0.01164439 0.01120722\n",
      " 0.01084375 0.01108451 0.01089929 0.01094233 0.01128174 0.01104567\n",
      " 0.011689   0.01088372 0.01095177 0.01122173 0.01123014 0.01128787\n",
      " 0.01136482 0.01121215 0.01100464 0.01117608 0.01138519 0.01131097]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.01072385 0.01073646 0.0112561  0.01095054 0.01131007 0.01076689\n",
      " 0.01106214 0.01082324 0.01129526 0.01089027 0.01120135 0.01115081\n",
      " 0.01118339 0.01125919 0.01096582 0.01140182 0.01105673 0.01115842\n",
      " 0.0111615  0.01091354 0.01103705 0.01116848 0.01089394 0.01094093\n",
      " 0.01090087 0.01081    0.01145801 0.0112925  0.01128611 0.01131246\n",
      " 0.01096727 0.01094467 0.0109474  0.01117606 0.01106558 0.01119182\n",
      " 0.01123983 0.01117378 0.01109405 0.01147355 0.01104945 0.0112143\n",
      " 0.0111087  0.01131097 0.01147302 0.01111888 0.01112041 0.01107123\n",
      " 0.01121611 0.01123492 0.01079431 0.01094816 0.01092295 0.01124739\n",
      " 0.01107851 0.01112928 0.01089048 0.01136709 0.01122437 0.01028036\n",
      " 0.01106542 0.01084821 0.01123741 0.01096168 0.01123999 0.01120793\n",
      " 0.01081465 0.0111836  0.01129363 0.01107319 0.0116446  0.01120597\n",
      " 0.01084533 0.01109898 0.01090901 0.01093819 0.01128579 0.01105329\n",
      " 0.01169714 0.01086922 0.01095074 0.01121421 0.01123374 0.01128143\n",
      " 0.0113469  0.01120151 0.01100338 0.01116839 0.01137728 0.01130659]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.01072296 0.01073725 0.0112558  0.01095128 0.01130969 0.01076679\n",
      " 0.01106259 0.01082321 0.01129504 0.01089031 0.01120086 0.01115065\n",
      " 0.01118332 0.01125924 0.01096486 0.01140209 0.01105786 0.01115856\n",
      " 0.01116148 0.01091301 0.01103684 0.01116785 0.01089408 0.01094138\n",
      " 0.01089973 0.01081027 0.0114569  0.01129267 0.01128503 0.01131301\n",
      " 0.01096635 0.01094462 0.01094791 0.01117613 0.01106459 0.01119104\n",
      " 0.01124041 0.01117368 0.01109464 0.01147272 0.01104997 0.01121323\n",
      " 0.01110884 0.0113108  0.01147398 0.01111847 0.01112009 0.01107124\n",
      " 0.01121692 0.01123421 0.01079414 0.0109482  0.01092381 0.01124694\n",
      " 0.0110778  0.01112868 0.01088979 0.01136814 0.01122485 0.01028176\n",
      " 0.01106644 0.01084823 0.01123649 0.01096237 0.01123917 0.01120791\n",
      " 0.01081417 0.01118293 0.01129279 0.0110735  0.01164493 0.01120622\n",
      " 0.01084613 0.01109954 0.01090921 0.01093826 0.01128641 0.01105351\n",
      " 0.01169721 0.01086903 0.01095047 0.0112153  0.0112341  0.01128295\n",
      " 0.01134738 0.01120155 0.01100399 0.01116762 0.01137802 0.01130563]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.01072271 0.01073198 0.01125344 0.01094846 0.01130933 0.01075852\n",
      " 0.01106048 0.01082492 0.01129535 0.01088881 0.01120519 0.01115344\n",
      " 0.01118589 0.01125598 0.01096514 0.01140199 0.0110564  0.01115583\n",
      " 0.01116239 0.01090732 0.01103662 0.01117003 0.01089459 0.01094569\n",
      " 0.0109026  0.01080991 0.01145683 0.0112931  0.01128794 0.01131373\n",
      " 0.01096495 0.01094087 0.01094975 0.01117287 0.01106516 0.01119138\n",
      " 0.01124368 0.0111726  0.0110949  0.01148442 0.01104754 0.01121292\n",
      " 0.01111291 0.0113103  0.01147617 0.01111564 0.01111926 0.01107249\n",
      " 0.01121917 0.01123607 0.0107991  0.01094843 0.0109282  0.01124439\n",
      " 0.01107912 0.01112701 0.01089234 0.01137143 0.01122692 0.01026168\n",
      " 0.01106894 0.0108482  0.01123521 0.01095093 0.01123474 0.0112053\n",
      " 0.01081462 0.01118746 0.01129514 0.01106963 0.01164094 0.01120439\n",
      " 0.01084581 0.01109859 0.01090894 0.01093806 0.01128629 0.01105062\n",
      " 0.01169783 0.0108748  0.01095145 0.01121979 0.01123133 0.01128227\n",
      " 0.01135361 0.01120551 0.011003   0.01117281 0.01138149 0.01130603]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.01072317 0.01073701 0.01125575 0.01095108 0.01130975 0.0107668\n",
      " 0.01106245 0.01082321 0.01129523 0.01089042 0.01120105 0.01115063\n",
      " 0.01118342 0.0112593  0.01096505 0.01140202 0.01105732 0.01115851\n",
      " 0.01116149 0.01091349 0.01103698 0.01116804 0.01089417 0.01094115\n",
      " 0.01090044 0.01081007 0.01145754 0.0112924  0.01128563 0.01131287\n",
      " 0.01096681 0.01094456 0.01094767 0.01117594 0.0110647  0.01119148\n",
      " 0.01124    0.01117364 0.01109438 0.01147293 0.0110498  0.0112135\n",
      " 0.01110881 0.01131095 0.01147368 0.01111856 0.01112044 0.01107143\n",
      " 0.01121656 0.01123449 0.01079427 0.01094823 0.01092341 0.01124703\n",
      " 0.0110783  0.01112897 0.01089009 0.01136756 0.01122471 0.01028136\n",
      " 0.01106588 0.01084825 0.01123692 0.01096197 0.01123982 0.01120774\n",
      " 0.01081434 0.01118326 0.01129303 0.01107343 0.0116448  0.01120608\n",
      " 0.01084579 0.01109925 0.01090914 0.01093812 0.01128599 0.01105352\n",
      " 0.0116972  0.01086909 0.01095073 0.01121501 0.01123382 0.01128211\n",
      " 0.01134712 0.01120142 0.01100381 0.01116793 0.0113776  0.01130616]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.01072177 0.01071132 0.01125836 0.01094483 0.01131393 0.01073711\n",
      " 0.01107457 0.01081751 0.01130721 0.01088319 0.01120335 0.01115671\n",
      " 0.01118023 0.01125542 0.01096611 0.01141109 0.01105142 0.01114514\n",
      " 0.0111653  0.0109011  0.01103602 0.01118725 0.01090098 0.01095135\n",
      " 0.01090571 0.01080619 0.01147226 0.0113031  0.01128036 0.01130274\n",
      " 0.01096549 0.01094807 0.01094317 0.01117566 0.01106615 0.01119696\n",
      " 0.01125281 0.01116951 0.01110323 0.01152164 0.01102167 0.01122055\n",
      " 0.01110569 0.01130299 0.01147244 0.01111534 0.01111969 0.01108245\n",
      " 0.01120759 0.01122644 0.01081442 0.01094243 0.01092563 0.01125872\n",
      " 0.01109358 0.0111353  0.01089403 0.01137281 0.01122852 0.01022695\n",
      " 0.01107218 0.01084562 0.01122891 0.01092786 0.01123063 0.01121853\n",
      " 0.01082646 0.01119551 0.01130515 0.01105263 0.01163805 0.01121362\n",
      " 0.01083594 0.0110976  0.01089769 0.01094706 0.01128257 0.0110338\n",
      " 0.01168669 0.01088238 0.01094989 0.0112132  0.01122133 0.01129149\n",
      " 0.01136762 0.01121332 0.01100197 0.01117165 0.01137472 0.01131431]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0.01072148 0.01073518 0.01125193 0.01094965 0.01130949 0.01075642\n",
      " 0.01106486 0.0108254  0.01129956 0.01088442 0.01120295 0.01115576\n",
      " 0.01118449 0.01125619 0.01096701 0.01140088 0.01105095 0.0111502\n",
      " 0.01116645 0.01090392 0.01103551 0.01116702 0.01090101 0.01094552\n",
      " 0.01089912 0.01080682 0.01146259 0.01130047 0.01128253 0.01131576\n",
      " 0.01096359 0.01094257 0.01094671 0.0111696  0.01106498 0.0111975\n",
      " 0.0112427  0.01117198 0.01109296 0.01148944 0.01104231 0.01120662\n",
      " 0.01110354 0.01130378 0.01147667 0.01111455 0.01112207 0.01107566\n",
      " 0.01121695 0.01123198 0.01080351 0.0109472  0.01092407 0.01125259\n",
      " 0.01108818 0.01113419 0.01089017 0.01137535 0.01123087 0.01025583\n",
      " 0.01107438 0.01085276 0.01122881 0.01094823 0.01122748 0.01121164\n",
      " 0.01081293 0.01118978 0.01129906 0.01107165 0.01164517 0.01121168\n",
      " 0.01084696 0.01109371 0.01090495 0.01093862 0.01128676 0.01104652\n",
      " 0.01169246 0.01087516 0.0109499  0.01121406 0.01122779 0.01129026\n",
      " 0.01135793 0.0112073  0.01100285 0.01117115 0.0113774  0.01131106]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "rs=model.predict(imgs[0:10])\n",
    "for i in range(len(rs)):\n",
    "    print(rs[i])\n",
    "    print(onehot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
